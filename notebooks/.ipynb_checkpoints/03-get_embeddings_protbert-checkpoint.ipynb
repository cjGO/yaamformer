{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ahead-algeria",
   "metadata": {},
   "source": [
    "## This notebook will demonstrate the huggingface API with the pretrained model, ProtBERT, to get embeddings for each of the available proteins in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "related-membrane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/glect/anaconda3/lib/python3.8/site-packages (4.15.0)\n",
      "Requirement already satisfied: sacremoses in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: filelock in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/glect/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: joblib in /home/glect/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: six in /home/glect/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /home/glect/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/glect/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/glect/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/glect/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/glect/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/glect/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/glect/.local/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chronic-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/glect/pytorch/yaamformer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "french-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "#import Auto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "Seqs,Labels = get_dataset('./data/YAAM.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-science",
   "metadata": {},
   "source": [
    "### Loading huggingface API for the ProtBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-tactics",
   "metadata": {},
   "source": [
    "Load the pre-trained model, pre-process the data, and collect the outputs from the model. Take the LAST hidden layer to be used for token classification. This is the protocol for using the feature embeddings for token classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "representations = []\n",
    "for i in tqdm(range(len(yaam))):\n",
    "    try:\n",
    "    #print(i)\n",
    "    sequence_Example = yaam['seqs'][i]\n",
    "    #print(sequence_Example)\n",
    "    sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)\n",
    "    sequence_Example = ' '.join(sequence_Example.replace('\\n',''))\n",
    "    encoded_input = tokenizer(sequence_Example, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input.to('cuda'),output_hidden_states=True)\n",
    "\n",
    "    representations.append(output['hidden_states'][-1])  # get last layers hidden state for classificaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-example",
   "metadata": {},
   "source": [
    "The tokens can be used now for standard classification with ML tools like random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-island",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
